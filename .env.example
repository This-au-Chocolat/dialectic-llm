# Environment variables for dialectic-llm
# Copy this file to .env and fill in your actual values

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Logging and Security
SANITIZE_SALT=your_random_salt_here

# Cost Controls
MAX_COST_USD=5.0
MAX_TOKENS_PER_ITEM=8000

# Default Models
DEFAULT_MODEL=gpt-4
BASELINE_TEMPERATURE=0.7

# === T-A-S Configuration ===
# Phase Temperatures (override configs/model.yaml)
TAS_THESIS_TEMPERATURE=0.7
TAS_ANTITHESIS_TEMPERATURE=0.5
TAS_SYNTHESIS_TEMPERATURE=0.2

# Model Configuration
TAS_DEFAULT_MODEL=gpt-4
TAS_FALLBACK_MODEL=gpt-3.5-turbo

# Token Limits
TAS_MAX_TOKENS_PER_PHASE=2000
TAS_TOTAL_TOKEN_LIMIT=6000

# Request Configuration
TAS_REQUEST_TIMEOUT=30
TAS_MAX_RETRIES=3

# T-A-S Parameters
TAS_K_VALUE=1

# Logging Behavior
TAS_SAVE_COT_LOCAL=true
TAS_SANITIZE_SHARED_LOGS=true
TAS_SESSION_TRACKING=true

# Prefect Configuration (optional)
PREFECT_API_URL=https://api.prefect.cloud/api/accounts/your-account/workspaces/your-workspace
