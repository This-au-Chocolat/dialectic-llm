# S1-10: Agregaci√≥n Parquet (Analytics)

## Descripci√≥n

S1-10 implementa la conversi√≥n autom√°tica de logs JSONL a formato Parquet para an√°lisis eficiente de datos. Este sistema permite agregar eventos por run_id y generar archivos Parquet optimizados para an√°lisis con pandas/pyarrow.

## Caracter√≠sticas Implementadas

### üîÑ Conversi√≥n JSONL ‚Üí Parquet
- **Conversi√≥n individual**: Un archivo JSONL ‚Üí un archivo Parquet
- **Conversi√≥n por directorio**: Todos los JSONL de un directorio
- **Agregaci√≥n por run**: Combinar eventos de m√∫ltiples archivos JSONL filtrados por run_id

### üìä Funcionalidades Analytics
- Preservaci√≥n de estructuras nested JSON
- Optimizaci√≥n con pyarrow backend
- Compresi√≥n autom√°tica de archivos Parquet
- Validaci√≥n de datos durante conversi√≥n

### üõ†Ô∏è CLI Completa
```bash
# Convertir archivo individual
python src/utils/jsonl_to_parquet.py file input.jsonl output.parquet

# Convertir directorio completo
python src/utils/jsonl_to_parquet.py directory logs/events analytics/parquet

# Agregar por run_id (funcionalidad principal S1-10)
python src/utils/jsonl_to_parquet.py aggregate run-baseline-001
```

## Uso B√°sico

### 1. Conversi√≥n Manual
```python
from utils.jsonl_to_parquet import convert_jsonl_to_parquet

# Convertir un archivo JSONL a Parquet
convert_jsonl_to_parquet(
    "logs/events/events_20251101.jsonl",
    "analytics/parquet/events_20251101.parquet"
)
```

### 2. Agregaci√≥n por Run (Principal S1-10)
```python
from utils.jsonl_to_parquet import aggregate_analytics_run

# Agregar todos los eventos de un run espec√≠fico
parquet_file = aggregate_analytics_run(
    run_id="baseline-run-001",
    events_dir="logs/events",
    output_dir="analytics/parquet"
)
# Resultado: analytics/parquet/run_baseline-run-001.parquet
```

### 3. An√°lisis con Pandas
```python
import pandas as pd

# Leer archivo Parquet para an√°lisis
df = pd.read_parquet("analytics/parquet/run_baseline-run-001.parquet")

# An√°lisis b√°sico
print(f"Total events: {len(df)}")
print(f"Unique problems: {df['problem_id'].nunique()}")

# An√°lisis de tokens
if 'tokens' in df.columns:
    total_tokens = df['tokens'].apply(lambda x: x.get('total_tokens', 0)).sum()
    print(f"Total tokens: {total_tokens:,}")

# An√°lisis de costos
if 'estimated_cost_usd' in df.columns:
    total_cost = df['estimated_cost_usd'].sum()
    print(f"Total cost: ${total_cost:.4f}")
```

## Integraci√≥n con Baseline Runner

### Demo Completo S1-10
```bash
# Ejecutar baseline con conversi√≥n autom√°tica a Parquet
python demo_s1_10_analytics.py --problems 10

# Analizar archivo Parquet existente
python demo_s1_10_analytics.py --analyze analytics/parquet/run_baseline-001.parquet
```

### Workflow Automatizado
```python
from demo_s1_10_analytics import run_baseline_with_analytics

# Ejecutar baseline + conversi√≥n autom√°tica
parquet_file = run_baseline_with_analytics(
    n_problems=200,
    model="gpt-4",
    auto_convert=True
)
```

## Estructura de Archivos

```
analytics/
‚îî‚îÄ‚îÄ parquet/
    ‚îú‚îÄ‚îÄ .gitkeep
    ‚îú‚îÄ‚îÄ events_20251101.parquet          # Conversi√≥n directa
    ‚îú‚îÄ‚îÄ run_baseline-001.parquet         # Agregaci√≥n por run_id
    ‚îî‚îÄ‚îÄ run_tas-experiment-001.parquet   # Futuras agregaciones T-A-S
```

## Esquema de Datos Parquet

Los archivos Parquet mantienen la estructura completa de los eventos JSONL:

| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| `run_id` | string | Identificador √∫nico del run |
| `problem_id` | string | ID del problema (ej: gsm8k-001) |
| `phase` | string | Fase del experimento (baseline, tas, etc.) |
| `timestamp` | string | ISO timestamp del evento |
| `model` | string | Modelo LLM utilizado |
| `tokens` | struct | Estructura con prompt_tokens, completion_tokens, total_tokens |
| `estimated_cost_usd` | double | Costo estimado en USD |
| `sanitization_info` | array | Metadata de sanitizaci√≥n aplicada |

## Ventajas del Formato Parquet

### üöÄ Performance
- **Lectura r√°pida**: 10-100x m√°s r√°pido que JSONL para an√°lisis
- **Compresi√≥n**: 70-90% menos espacio que JSONL
- **Queries columnar**: Ideal para agregaciones y filtros

### üîç An√°lisis
- **Pandas integraci√≥n**: Lectura nativa con `pd.read_parquet()`
- **Schema validation**: Tipos de datos consistentes
- **Nested structures**: Soporte completo para JSON nested

### üîß Operacional
- **Append support**: F√°cil agregaci√≥n de nuevos datos
- **Metadata**: Preserva informaci√≥n de esquema
- **Cross-platform**: Compatible con Spark, R, Python

## Tests

El sistema incluye tests completos:

```bash
# Ejecutar tests espec√≠ficos de S1-10
python -m pytest tests/test_jsonl_to_parquet.py -v

# Tests cubiertos:
# ‚úÖ Conversi√≥n individual JSONL ‚Üí Parquet
# ‚úÖ Conversi√≥n por directorio
# ‚úÖ Agregaci√≥n por run_id
# ‚úÖ Manejo de estructuras nested
# ‚úÖ Archivos vac√≠os
```

## Criterios S1-10 Cumplidos

- ‚úÖ **Job que convierte JSONL‚ÜíParquet por run**: `aggregate_analytics_run()`
- ‚úÖ **Archivo `/analytics/parquet/*.parquet`**: Generaci√≥n autom√°tica
- ‚úÖ **Legible con pandas/pyarrow**: Compatibilidad completa
- ‚úÖ **4h estimadas - Jos√©**: Implementaci√≥n completa

## Pr√≥ximos Pasos

S1-10 est√° **listo para S1-13** (McNemar + KPIs), que utilizar√° estos archivos Parquet para:
- An√°lisis estad√≠stico baseline vs T-A-S
- C√°lculo de ŒîAcc y tokens
- Generaci√≥n de reportes tabulares

## Comandos de Ejemplo

```bash
# Conversi√≥n b√°sica
python src/utils/jsonl_to_parquet.py file logs/events/events_20251101.jsonl analytics/parquet/events.parquet

# Conversi√≥n masiva
python src/utils/jsonl_to_parquet.py directory logs/events analytics/parquet

# Agregaci√≥n espec√≠fica (S1-10 principal)
python src/utils/jsonl_to_parquet.py aggregate baseline-run-001

# Demo completo con baseline
python demo_s1_10_analytics.py --problems 5

# An√°lisis de resultados
python demo_s1_10_analytics.py --analyze analytics/parquet/run_baseline-001.parquet
```
